{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776fca2b",
   "metadata": {},
   "source": [
    "##### Load the nb_black formatter\n",
    "pip install nb_black or conda install nb_black -- if not installed already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b7461a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be6ac8",
   "metadata": {},
   "source": [
    "#### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50dca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Importing User-defined functions from utilis\\nfrom main_utilis import read_data, data_from_to_numpy, std_normalise_data\\nfrom utils import augment_data, standard_model\\nfrom equi_nn_utilis import (\\n    EquivariantHiddenLayer,\\n    EquivariantOutputLayer,\\n    eq_build_model,\\n)\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_formatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Importing User-defined functions from utilis\\nfrom main_utilis import read_data, data_from_to_numpy, std_normalise_data\\nfrom utils import augment_data, standard_model\\nfrom equi_nn_utilis import (\\n    EquivariantHiddenLayer,\\n    EquivariantOutputLayer,\\n    eq_build_model,\\n)\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Importing User-defined functions from utilis\\nfrom main_utilis import read_data, data_from_to_numpy, std_normalise_data\\nfrom utils import augment_data, standard_model\\nfrom equi_nn_utilis import (\\n    EquivariantHiddenLayer,\\n    EquivariantOutputLayer,\\n    eq_build_model,\\n)\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_formatted_code = \"# Importing required libraries\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib as plt\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers\\nimport keras_tuner as kt\\nfrom tensorflow import keras\\n\\n# Importing specific modules from libraries\\nfrom keras_tuner.tuners import RandomSearch\\nfrom keras_tuner.engine.hyperparameters import HyperParameters\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\\nfrom tensorflow.keras.callbacks import EarlyStopping\\n\\n# Importing User-defined functions from utilis\\nfrom main_utilis import read_data, data_from_to_numpy, std_normalise_data\\nfrom utils import augment_data, standard_model\\nfrom equi_nn_utilis import (\\n    EquivariantHiddenLayer,\\n    EquivariantOutputLayer,\\n    eq_build_model,\\n)\\n\\n# Setting numpy print options to display floating point numbers up to 3 decimal points\\nnp.set_printoptions(precision=3, suppress=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "# Importing specific modules from libraries\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Importing User-defined functions from utilis\n",
    "from main_utilis import read_data, data_from_to_numpy, std_normalise_data\n",
    "from utils import augment_data, standard_model\n",
    "from equi_nn_utilis import (\n",
    "    EquivariantHiddenLayer,\n",
    "    EquivariantOutputLayer,\n",
    "    eq_build_model,\n",
    ")\n",
    "\n",
    "# Setting numpy print options to display floating point numbers up to 3 decimal points\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7226b5",
   "metadata": {},
   "source": [
    "### 1. Load the datasets\n",
    "\n",
    "leakage dataset train [m].csv \n",
    "\n",
    "leakage dataset validation 1000.csv\n",
    "\n",
    "and store the data as NumPy-Arrays\n",
    "X train, Y train\n",
    "X validation, Y validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbbddc",
   "metadata": {},
   "source": [
    "#### Loading the data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba15da34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"df_100, df_1000, df_val = read_data()\";\n",
       "                var nbb_formatted_code = \"df_100, df_1000, df_val = read_data()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_100, df_1000, df_val = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995518ff",
   "metadata": {},
   "source": [
    "#### Load the features and label from dataframe and convert it to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae65ae78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"X_train_100, y_train_100, X_train_1000, y_train_1000, X_val, y_val = data_from_to_numpy(\\n    df_100, df_1000, df_val\\n)\";\n",
       "                var nbb_formatted_code = \"X_train_100, y_train_100, X_train_1000, y_train_1000, X_val, y_val = data_from_to_numpy(\\n    df_100, df_1000, df_val\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_100, y_train_100, X_train_1000, y_train_1000, X_val, y_val = data_from_to_numpy(\n",
    "    df_100, df_1000, df_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1e288",
   "metadata": {},
   "source": [
    "####  Standardize and normalize the data\n",
    "For that purpose, you have training data (xi, yi)\n",
    "mi=1 available. Unfortunately,\n",
    "the fourth sensor MFC4 had a slight malfunction at the time when the training data were produced. As a consequence, the values x4 are on average\n",
    "higher than their counterparts x1, x2 and x3. Be aware that the same effect\n",
    "is not present in the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66339be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"X_train_100_norm, X_train_1000_norm, X_val_norm = std_normalise_data(\\n    X_train_100, X_train_1000, X_val\\n)\";\n",
       "                var nbb_formatted_code = \"X_train_100_norm, X_train_1000_norm, X_val_norm = std_normalise_data(\\n    X_train_100, X_train_1000, X_val\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_100_norm, X_train_1000_norm, X_val_norm = std_normalise_data(\n",
    "    X_train_100, X_train_1000, X_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea930494",
   "metadata": {},
   "source": [
    "### Train a standard fully connected neural network without hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f247ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        64,\n",
    "        activation=\"relu\",\n",
    "        input_shape=(4,),\n",
    "    )\n",
    ")\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "# model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "#\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=\"mean_absolute_error\",\n",
    "    metrics=[\"accuracy\", \"mean_absolute_error\"],\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_1000_norm,\n",
    "    y_train_1000,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46966ffc",
   "metadata": {},
   "source": [
    "### 2. Train a standard fully connected neural network. Hyperparameters\n",
    "\n",
    "like number of epochs, batch size, optimizer, learning rate, depth and\n",
    "width of the network, activation and loss functions – all up to you. You\n",
    "can use a framework like KerasTuner to optimize hyperparameters, or\n",
    "simple for-loops if you prefer that. Anyway, you should use the validation data in order to evaluate and compare candidate hyperparameter\n",
    "configurations. Save the model as model standard [m].h5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bcb9d0",
   "metadata": {},
   "source": [
    "### For Normalised Dataset with 100 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca107e3",
   "metadata": {},
   "source": [
    "#### Instantiate the tuner and define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tuner and define search space\n",
    "tuner_1 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"standard_model_100\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Define the search strategy\n",
    "tuner_1.search(\n",
    "    X_train_100_norm,\n",
    "    y_train_100,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd68dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner_1.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_100 = tuner_1.hypermodel.build(best_hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp_100.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c11ea",
   "metadata": {},
   "source": [
    "#### Calling Hyperparameters in the required model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (X_train_1000_norm.shape[1],)\n",
    "\n",
    "# Define the model architecture using the hyperparameters\n",
    "model_100 = keras.Sequential()\n",
    "model_100.add(Dense(units=best_hps.values['input_units'], activation=best_hps.values['input_activation'], input_shape=input_shape))\n",
    "for i in range(best_hps.values['num_layers']):\n",
    "    model_100.add(Dense(units=best_hps.values[f'hidden_{i+1}_units'], activation=best_hps.values[f'hidden_{i+1}_activation']))\n",
    "model_100.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "# Compile the model using the hyperparameters\n",
    "optimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps.values['learning_rate']))\n",
    "model_100.compile(optimizer=optimizer, loss=best_hps.values['loss'], metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Fit the model using the hyperparameters\n",
    "history_100 = model_100.fit(X_train_100_norm, y_train_100, batch_size=best_hps.values['batch_size'], epochs=best_hps.values['num_epochs'],callbacks=[early_stop], validation_data=(X_val_norm, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5238871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91592a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "model_100.save(\"models/model_standard_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Evaluate the model on the validation dataset\n",
    "new_model_100 = tf.keras.models.load_model(\"models/model_standard_100.h5\")\n",
    "val_metrics_100 = new_model_100.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_100.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cbe381",
   "metadata": {},
   "source": [
    "### For Normalised Dataset with 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tuner and define search space\n",
    "tuner_2 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"standard_model_1000\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Define the search strategy\n",
    "tuner_2.search(\n",
    "    X_train_1000_norm,\n",
    "    y_train_1000,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps_1000 = tuner_2.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_1000 = tuner_2.hypermodel.build(best_hps_1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93664cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps_1000.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89324088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp_1000.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (X_train_1000_norm.shape[1],)\n",
    "\n",
    "# Define the model architecture using the hyperparameters\n",
    "model_1000 = keras.Sequential()\n",
    "model_1000.add(Dense(units=best_hps_1000.values['input_units'], activation=best_hps_1000.values['input_activation'], input_shape=input_shape))\n",
    "for i in range(best_hps_1000.values['num_layers']):\n",
    "    model_1000.add(Dense(units=best_hps_1000.values[f'hidden_{i+1}_units'], activation=best_hps_1000.values[f'hidden_{i+1}_activation']))\n",
    "model_1000.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "# Compile the model using the hyperparameters\n",
    "optimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps_1000.values['learning_rate']))\n",
    "model_1000.compile(optimizer=optimizer, loss=best_hps_1000.values['loss'], metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Fit the model using the hyperparameters\n",
    "history_1000 = model_1000.fit(X_train_1000_norm, y_train_1000, batch_size=best_hps_1000.values['batch_size'], epochs=best_hps_1000.values['num_epochs'],callbacks=[early_stop] ,validation_data=(X_val_norm, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "model_1000.save(\"models/model_standard_1000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87543e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Evaluate the model on the validation dataset\n",
    "new_model_1000 = tf.keras.models.load_model(\"models/model_standard_1000.h5\")\n",
    "val_metrics_1000 = new_model_1000.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c46a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_1000.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02efe1",
   "metadata": {},
   "source": [
    "### 3. Augment the dataset. \n",
    "\n",
    "Each training example (x, y) can be complemented by seven additional virtual examples as illustrated in Figure 1.\n",
    "Clockwise rotations and flips on input data x are obtained as described\n",
    "above. A clockwise rotation on output data y is obtained through\n",
    "y90 = (y2, −y1) and a flip along the vertical axis on the same data is\n",
    "represented by yf lipped = (−y1, y2). All other operations (rotation angles and associated flips) can be computed by subsequent application\n",
    "of these two operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14451bd2",
   "metadata": {},
   "source": [
    "#### Function to augment the data and insert into training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af83a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Augment the training data with the augment_data function for the training\\nx_train_augmented, y_train_augmented = augment_data(X_train_100_norm, y_train_100)\\nx_train_augmented_1000, y_train_augmented_1000 = augment_data(\\n    X_train_1000_norm, y_train_1000\\n)\";\n",
       "                var nbb_formatted_code = \"# Augment the training data with the augment_data function for the training\\nx_train_augmented, y_train_augmented = augment_data(X_train_100_norm, y_train_100)\\nx_train_augmented_1000, y_train_augmented_1000 = augment_data(\\n    X_train_1000_norm, y_train_1000\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Augment the training data with the augment_data function for the training\n",
    "x_train_augmented, y_train_augmented = augment_data(X_train_100_norm, y_train_100)\n",
    "x_train_augmented_1000, y_train_augmented_1000 = augment_data(\n",
    "    X_train_1000_norm, y_train_1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ac6282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Convert the augmented data and labels to numpy arrays\\nX_train_augmented = np.array(x_train_augmented)\\ny_train_augmented = np.array(y_train_augmented)\\nX_train_augmented_1000 = np.array(x_train_augmented_1000)\\ny_train_augmented_1000 = np.array(y_train_augmented_1000)\";\n",
       "                var nbb_formatted_code = \"# Convert the augmented data and labels to numpy arrays\\nX_train_augmented = np.array(x_train_augmented)\\ny_train_augmented = np.array(y_train_augmented)\\nX_train_augmented_1000 = np.array(x_train_augmented_1000)\\ny_train_augmented_1000 = np.array(y_train_augmented_1000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the augmented data and labels to numpy arrays\n",
    "X_train_augmented = np.array(x_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "X_train_augmented_1000 = np.array(x_train_augmented_1000)\n",
    "y_train_augmented_1000 = np.array(y_train_augmented_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed9bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.4951 - mean_absolute_error: 0.5066 - val_loss: 0.5006 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5006\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.4942 - mean_absolute_error: 0.5057 - val_loss: 0.5003 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5003\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.5002 - mean_absolute_error: 0.5057 - val_loss: 0.5013 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5013\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.4967 - mean_absolute_error: 0.5059 - val_loss: 0.5003 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5003\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.4888 - mean_absolute_error: 0.5057 - val_loss: 0.5005 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5005\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.5040 - mean_absolute_error: 0.5057 - val_loss: 0.5007 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5007\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.4947 - mean_absolute_error: 0.5053 - val_loss: 0.5010 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5010\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.4925 - mean_absolute_error: 0.5059 - val_loss: 0.5007 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5007\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.4925 - mean_absolute_error: 0.5057 - val_loss: 0.5012 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5012\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.5027 - mean_absolute_error: 0.5056 - val_loss: 0.5011 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5011\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.4988 - mean_absolute_error: 0.5056 - val_loss: 0.5009 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5009\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.4975 - mean_absolute_error: 0.5056 - val_loss: 0.5019 - val_accuracy: 0.4960 - val_mean_absolute_error: 0.5019\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.4990 - mean_absolute_error: 0.5058 - val_loss: 0.5003 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5003\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.4980 - mean_absolute_error: 0.5056 - val_loss: 0.5003 - val_accuracy: 0.5040 - val_mean_absolute_error: 0.5003\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"model_1 = tf.keras.Sequential()\\nmodel_1.add(\\n    tf.keras.layers.Dense(\\n        128,\\n        activation=\\\"relu\\\",\\n        input_shape=(4,),\\n    )\\n)\\nmodel_1.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n\\nmodel_1.add(tf.keras.layers.Dense(2, activation=\\\"linear\\\"))\\n\\n# Compile the model\\nmodel_1.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\\n    loss=\\\"mean_absolute_error\\\",\\n    metrics=[\\\"accuracy\\\", \\\"mean_absolute_error\\\"],\\n)\\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Train the model\\nhistory = model_1.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    validation_data=(X_val_norm, y_val),\\n    batch_size=32,\\n    epochs=100,\\n    callbacks=[callback],\\n)\";\n",
       "                var nbb_formatted_code = \"model_1 = tf.keras.Sequential()\\nmodel_1.add(\\n    tf.keras.layers.Dense(\\n        128,\\n        activation=\\\"relu\\\",\\n        input_shape=(4,),\\n    )\\n)\\nmodel_1.add(tf.keras.layers.Dense(32, activation=\\\"relu\\\"))\\n\\nmodel_1.add(tf.keras.layers.Dense(2, activation=\\\"linear\\\"))\\n\\n# Compile the model\\nmodel_1.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\\n    loss=\\\"mean_absolute_error\\\",\\n    metrics=[\\\"accuracy\\\", \\\"mean_absolute_error\\\"],\\n)\\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Train the model\\nhistory = model_1.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    validation_data=(X_val_norm, y_val),\\n    batch_size=32,\\n    epochs=100,\\n    callbacks=[callback],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        128,\n",
    "        activation=\"relu\",\n",
    "        input_shape=(4,),\n",
    "    )\n",
    ")\n",
    "model_1.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(2, activation=\"linear\"))\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=\"mean_absolute_error\",\n",
    "    metrics=[\"accuracy\", \"mean_absolute_error\"],\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Train the model\n",
    "history = model_1.fit(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a7c37",
   "metadata": {},
   "source": [
    "### For Augmeted Dataset after normalisation with 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe6b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 10s]\n",
      "val_loss: 0.5697615742683411\n",
      "\n",
      "Best val_loss So Far: 0.5594862103462219\n",
      "Total elapsed time: 00h 16m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Instantiate the tuner and define search space\\ntuner_3 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"standard_model_100_augmented\\\",\\n)\\n\\n\\n# Define early stopping\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Define the search strategy\\ntuner_3.search(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=200,\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop],\\n)\";\n",
       "                var nbb_formatted_code = \"# Instantiate the tuner and define search space\\ntuner_3 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"standard_model_100_augmented\\\",\\n)\\n\\n\\n# Define early stopping\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Define the search strategy\\ntuner_3.search(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=200,\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the tuner and define search space\n",
    "tuner_3 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"standard_model_100_augmented\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Define the search strategy\n",
    "tuner_3.search(\n",
    "    X_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e05821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"best_hps_100_aug = tuner_3.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_100_aug = tuner_3.hypermodel.build(best_hps_100_aug)\";\n",
       "                var nbb_formatted_code = \"best_hps_100_aug = tuner_3.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_100_aug = tuner_3.hypermodel.build(best_hps_100_aug)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_100_aug = tuner_3.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_100_aug = tuner_3.hypermodel.build(best_hps_100_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa27925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 1,\n",
       " 'layer_size_range': 496,\n",
       " 'input_units': 64,\n",
       " 'input_activation': 'tanh',\n",
       " 'hidden_1_units': 32,\n",
       " 'hidden_1_activation': 'tanh',\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.0001,\n",
       " 'loss': 'mean_squared_error',\n",
       " 'batch_size': 48,\n",
       " 'num_epochs': 70,\n",
       " 'hidden_2_units': 64,\n",
       " 'hidden_2_activation': 'tanh',\n",
       " 'hidden_3_units': 64,\n",
       " 'hidden_3_activation': 'sigmoid',\n",
       " 'hidden_4_units': 32,\n",
       " 'hidden_4_activation': 'relu',\n",
       " 'tuner/epochs': 23,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"best_hps_100_aug.values\";\n",
       "                var nbb_formatted_code = \"best_hps_100_aug.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_100_aug.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e399fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,466\n",
      "Trainable params: 2,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"model_hp_100_aug.summary()\";\n",
       "                var nbb_formatted_code = \"model_hp_100_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hp_100_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e31dcf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 0.3508 - mae: 0.5107 - val_loss: 0.3519 - val_mae: 0.5142\n",
      "Epoch 2/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3479 - mae: 0.5092 - val_loss: 0.3483 - val_mae: 0.5119\n",
      "Epoch 3/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3472 - mae: 0.5091 - val_loss: 0.3470 - val_mae: 0.5110\n",
      "Epoch 4/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3468 - mae: 0.5089 - val_loss: 0.3456 - val_mae: 0.5101\n",
      "Epoch 5/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3465 - mae: 0.5088 - val_loss: 0.3448 - val_mae: 0.5096\n",
      "Epoch 6/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3466 - mae: 0.5090 - val_loss: 0.3434 - val_mae: 0.5086\n",
      "Epoch 7/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3461 - mae: 0.5087 - val_loss: 0.3407 - val_mae: 0.5067\n",
      "Epoch 8/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3462 - mae: 0.5089 - val_loss: 0.3402 - val_mae: 0.5064\n",
      "Epoch 9/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3460 - mae: 0.5088 - val_loss: 0.3407 - val_mae: 0.5069\n",
      "Epoch 10/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3459 - mae: 0.5086 - val_loss: 0.3395 - val_mae: 0.5061\n",
      "Epoch 11/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3458 - mae: 0.5087 - val_loss: 0.3378 - val_mae: 0.5049\n",
      "Epoch 12/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3456 - mae: 0.5086 - val_loss: 0.3373 - val_mae: 0.5045\n",
      "Epoch 13/70\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3456 - mae: 0.5087 - val_loss: 0.3361 - val_mae: 0.5037\n",
      "Epoch 14/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3455 - mae: 0.5086 - val_loss: 0.3359 - val_mae: 0.5036\n",
      "Epoch 15/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3455 - mae: 0.5087 - val_loss: 0.3357 - val_mae: 0.5034\n",
      "Epoch 16/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3454 - mae: 0.5086 - val_loss: 0.3349 - val_mae: 0.5029\n",
      "Epoch 17/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3454 - mae: 0.5086 - val_loss: 0.3351 - val_mae: 0.5031\n",
      "Epoch 18/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3456 - mae: 0.5088 - val_loss: 0.3353 - val_mae: 0.5033\n",
      "Epoch 19/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - mae: 0.5086 - val_loss: 0.3344 - val_mae: 0.5026\n",
      "Epoch 20/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - mae: 0.5086 - val_loss: 0.3349 - val_mae: 0.5030\n",
      "Epoch 21/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3342 - val_mae: 0.5025\n",
      "Epoch 22/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - mae: 0.5086 - val_loss: 0.3342 - val_mae: 0.5025\n",
      "Epoch 23/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - mae: 0.5086 - val_loss: 0.3333 - val_mae: 0.5018\n",
      "Epoch 24/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3454 - mae: 0.5087 - val_loss: 0.3332 - val_mae: 0.5018\n",
      "Epoch 25/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3331 - val_mae: 0.5018\n",
      "Epoch 26/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3329 - val_mae: 0.5016\n",
      "Epoch 27/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3454 - mae: 0.5087 - val_loss: 0.3314 - val_mae: 0.5005\n",
      "Epoch 28/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5085 - val_loss: 0.3323 - val_mae: 0.5012\n",
      "Epoch 29/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5086 - val_loss: 0.3323 - val_mae: 0.5011\n",
      "Epoch 30/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3319 - val_mae: 0.5008\n",
      "Epoch 31/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5085 - val_loss: 0.3309 - val_mae: 0.5001\n",
      "Epoch 32/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5085 - val_loss: 0.3311 - val_mae: 0.5003\n",
      "Epoch 33/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - mae: 0.5087 - val_loss: 0.3302 - val_mae: 0.4996\n",
      "Epoch 34/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3451 - mae: 0.5086 - val_loss: 0.3314 - val_mae: 0.5005\n",
      "Epoch 35/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3303 - val_mae: 0.4997\n",
      "Epoch 36/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3295 - val_mae: 0.4991\n",
      "Epoch 37/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3451 - mae: 0.5086 - val_loss: 0.3310 - val_mae: 0.5002\n",
      "Epoch 38/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3304 - val_mae: 0.4998\n",
      "Epoch 39/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3310 - val_mae: 0.5002\n",
      "Epoch 40/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5086 - val_loss: 0.3306 - val_mae: 0.4999\n",
      "Epoch 41/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3451 - mae: 0.5086 - val_loss: 0.3312 - val_mae: 0.5003\n",
      "Epoch 42/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5087 - val_loss: 0.3312 - val_mae: 0.5004\n",
      "Epoch 43/70\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3451 - mae: 0.5085 - val_loss: 0.3315 - val_mae: 0.5006\n",
      "Epoch 44/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5085 - val_loss: 0.3318 - val_mae: 0.5008\n",
      "Epoch 45/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - mae: 0.5086 - val_loss: 0.3315 - val_mae: 0.5006\n",
      "Epoch 46/70\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3451 - mae: 0.5085 - val_loss: 0.3318 - val_mae: 0.5008\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Define the input shape\\ninput_shape = (X_train_augmented_1000.shape[1],)\\n\\n# Define the model architecture using the hyperparameters\\nmodel_100_aug = keras.Sequential()\\nmodel_100_aug.add(Dense(units=best_hps_100_aug.values['input_units'], activation=best_hps_100_aug.values['input_activation'], input_shape=input_shape))\\nfor i in range(best_hps_100_aug.values['num_layers']):\\n    model_100_aug.add(Dense(units=best_hps_100_aug.values[f'hidden_{i+1}_units'], activation=best_hps_100_aug.values[f'hidden_{i+1}_activation']))\\nmodel_100_aug.add(Dense(units=2, activation='linear'))\\n\\n# Compile the model using the hyperparameters\\noptimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps_100_aug.values['learning_rate']))\\nmodel_100_aug.compile(optimizer=optimizer, loss=best_hps_100_aug.values['loss'], metrics=['mae'])\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Fit the model using the hyperparameters\\nhistory_100_aug = model_100_aug.fit(X_train_augmented, y_train_augmented, batch_size=best_hps_100_aug.values['batch_size'], epochs=best_hps_100_aug.values['num_epochs'],callbacks=[early_stop], validation_data=(X_val_norm, y_val))\";\n",
       "                var nbb_formatted_code = \"# Define the input shape\\ninput_shape = (X_train_augmented_1000.shape[1],)\\n\\n# Define the model architecture using the hyperparameters\\nmodel_100_aug = keras.Sequential()\\nmodel_100_aug.add(\\n    Dense(\\n        units=best_hps_100_aug.values[\\\"input_units\\\"],\\n        activation=best_hps_100_aug.values[\\\"input_activation\\\"],\\n        input_shape=input_shape,\\n    )\\n)\\nfor i in range(best_hps_100_aug.values[\\\"num_layers\\\"]):\\n    model_100_aug.add(\\n        Dense(\\n            units=best_hps_100_aug.values[f\\\"hidden_{i+1}_units\\\"],\\n            activation=best_hps_100_aug.values[f\\\"hidden_{i+1}_activation\\\"],\\n        )\\n    )\\nmodel_100_aug.add(Dense(units=2, activation=\\\"linear\\\"))\\n\\n# Compile the model using the hyperparameters\\noptimizer = tf.keras.optimizers.Adam(\\n    learning_rate=best_hps_100_aug.values[\\\"learning_rate\\\"]\\n)\\nmodel_100_aug.compile(\\n    optimizer=optimizer, loss=best_hps_100_aug.values[\\\"loss\\\"], metrics=[\\\"mae\\\"]\\n)\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Fit the model using the hyperparameters\\nhistory_100_aug = model_100_aug.fit(\\n    X_train_augmented,\\n    y_train_augmented,\\n    batch_size=best_hps_100_aug.values[\\\"batch_size\\\"],\\n    epochs=best_hps_100_aug.values[\\\"num_epochs\\\"],\\n    callbacks=[early_stop],\\n    validation_data=(X_val_norm, y_val),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (X_train_augmented_1000.shape[1],)\n",
    "\n",
    "# Define the model architecture using the hyperparameters\n",
    "model_100_aug = keras.Sequential()\n",
    "model_100_aug.add(Dense(units=best_hps_100_aug.values['input_units'], activation=best_hps_100_aug.values['input_activation'], input_shape=input_shape))\n",
    "for i in range(best_hps_100_aug.values['num_layers']):\n",
    "    model_100_aug.add(Dense(units=best_hps_100_aug.values[f'hidden_{i+1}_units'], activation=best_hps_100_aug.values[f'hidden_{i+1}_activation']))\n",
    "model_100_aug.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "# Compile the model using the hyperparameters\n",
    "optimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps_100_aug.values['learning_rate']))\n",
    "model_100_aug.compile(optimizer=optimizer, loss=best_hps_100_aug.values['loss'], metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Fit the model using the hyperparameters\n",
    "history_100_aug = model_100_aug.fit(X_train_augmented, y_train_augmented, batch_size=best_hps_100_aug.values['batch_size'], epochs=best_hps_100_aug.values['num_epochs'],callbacks=[early_stop], validation_data=(X_val_norm, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0527a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,466\n",
      "Trainable params: 2,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"model_100_aug.summary()\";\n",
       "                var nbb_formatted_code = \"model_100_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_100_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b8448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Save the Model\\nmodel_100_aug.save(\\\"models/model_standard_100_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Save the Model\\nmodel_100_aug.save(\\\"models/model_standard_100_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the Model\n",
    "model_100_aug.save(\"models/model_standard_100_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a70fd068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 903us/step - loss: 0.3318 - mae: 0.5008\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Load and Evaluate the model on the validation dataset\\nnew_model_100_aug = tf.keras.models.load_model(\\\"models/model_standard_100_augmented.h5\\\")\\n\\nval_metrics_100_aug = new_model_100_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_formatted_code = \"# Load and Evaluate the model on the validation dataset\\nnew_model_100_aug = tf.keras.models.load_model(\\\"models/model_standard_100_augmented.h5\\\")\\n\\nval_metrics_100_aug = new_model_100_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and Evaluate the model on the validation dataset\n",
    "new_model_100_aug = tf.keras.models.load_model(\"models/model_standard_100_augmented.h5\")\n",
    "\n",
    "val_metrics_100_aug = new_model_100_aug.evaluate(X_val_norm, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b907a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,466\n",
      "Trainable params: 2,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"new_model_100_aug.summary()\";\n",
       "                var nbb_formatted_code = \"new_model_100_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_100_aug.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f9802",
   "metadata": {},
   "source": [
    "### For Augmeted Dataset after normalisation with 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34570895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 21s]\n",
      "val_loss: 0.5700260400772095\n",
      "\n",
      "Best val_loss So Far: 0.5531229376792908\n",
      "Total elapsed time: 00h 31m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Instantiate the tuner and define search space\\ntuner_4 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"standard_model_1000_augmented\\\",\\n)\\n\\n# Define early stopping\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Define the search strategy\\ntuner_4.search(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=200,\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop],\\n)\";\n",
       "                var nbb_formatted_code = \"# Instantiate the tuner and define search space\\ntuner_4 = kt.Hyperband(\\n    hypermodel=standard_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"standard_model_1000_augmented\\\",\\n)\\n\\n# Define early stopping\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n# Define the search strategy\\ntuner_4.search(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=200,\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the tuner and define search space\n",
    "tuner_4 = kt.Hyperband(\n",
    "    hypermodel=standard_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"standard_model_1000_augmented\",\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "# Define the search strategy\n",
    "tuner_4.search(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    epochs=200,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e40438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"best_hps_1000_aug = tuner_4.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_1000_aug = tuner_4.hypermodel.build(best_hps_1000_aug)\";\n",
       "                var nbb_formatted_code = \"best_hps_1000_aug = tuner_4.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_1000_aug = tuner_4.hypermodel.build(best_hps_1000_aug)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_1000_aug = tuner_4.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_1000_aug = tuner_4.hypermodel.build(best_hps_1000_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0602554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 1,\n",
       " 'layer_size_range': 80,\n",
       " 'input_units': 64,\n",
       " 'input_activation': 'tanh',\n",
       " 'hidden_1_units': 48,\n",
       " 'hidden_1_activation': 'tanh',\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 0.01,\n",
       " 'loss': 'mean_squared_error',\n",
       " 'batch_size': 112,\n",
       " 'num_epochs': 170,\n",
       " 'hidden_2_units': 144,\n",
       " 'hidden_2_activation': 'tanh',\n",
       " 'hidden_3_units': 992,\n",
       " 'hidden_3_activation': 'sigmoid',\n",
       " 'hidden_4_units': 272,\n",
       " 'hidden_4_activation': 'relu',\n",
       " 'tuner/epochs': 23,\n",
       " 'tuner/initial_epoch': 8,\n",
       " 'tuner/bracket': 4,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0111'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"best_hps_1000_aug.values\";\n",
       "                var nbb_formatted_code = \"best_hps_1000_aug.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_1000_aug.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4d9614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 48)                3120      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,538\n",
      "Trainable params: 3,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"model_hp_1000_aug.summary()\";\n",
       "                var nbb_formatted_code = \"model_hp_1000_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_hp_1000_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176c96ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "72/72 [==============================] - 1s 3ms/step - loss: 0.3429 - mae: 0.5071 - val_loss: 0.3033 - val_mae: 0.4777\n",
      "Epoch 2/170\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3378 - mae: 0.5056 - val_loss: 0.3171 - val_mae: 0.4892\n",
      "Epoch 3/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3369 - mae: 0.5052 - val_loss: 0.3329 - val_mae: 0.5017\n",
      "Epoch 4/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3371 - mae: 0.5056 - val_loss: 0.3345 - val_mae: 0.5029\n",
      "Epoch 5/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3365 - mae: 0.5053 - val_loss: 0.3299 - val_mae: 0.4995\n",
      "Epoch 6/170\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3366 - mae: 0.5053 - val_loss: 0.3310 - val_mae: 0.5004\n",
      "Epoch 7/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3368 - mae: 0.5055 - val_loss: 0.3266 - val_mae: 0.4967\n",
      "Epoch 8/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3367 - mae: 0.5054 - val_loss: 0.3304 - val_mae: 0.4998\n",
      "Epoch 9/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3369 - mae: 0.5056 - val_loss: 0.3299 - val_mae: 0.4994\n",
      "Epoch 10/170\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3369 - mae: 0.5055 - val_loss: 0.3290 - val_mae: 0.4986\n",
      "Epoch 11/170\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3368 - mae: 0.5052 - val_loss: 0.3338 - val_mae: 0.5021\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Define the input shape\\ninput_shape = (X_train_augmented_1000.shape[1],)\\n\\n# Define the model architecture using the hyperparameters\\nmodel_1000_aug = keras.Sequential()\\nmodel_1000_aug.add(Dense(units=best_hps_1000_aug.values['input_units'], activation=best_hps_1000_aug.values['input_activation'], input_shape=input_shape))\\nfor i in range(best_hps_1000_aug.values['num_layers']):\\n    model_1000_aug.add(Dense(units=best_hps_1000_aug.values[f'hidden_{i+1}_units'], activation=best_hps_1000_aug.values[f'hidden_{i+1}_activation']))\\nmodel_1000_aug.add(Dense(units=2, activation='linear'))\\n\\n# Compile the model using the hyperparameters\\noptimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps_1000_aug.values['learning_rate']))\\nmodel_1000_aug.compile(optimizer=optimizer, loss=best_hps_1000_aug.values['loss'], metrics=['mae'])\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Fit the model using the hyperparameters\\nhistory_1000_aug = model_1000_aug.fit(X_train_augmented_1000, y_train_augmented_1000, batch_size=best_hps_1000_aug.values['batch_size'], epochs=best_hps_1000_aug.values['num_epochs'],callbacks=[early_stop], validation_data=(X_val_norm, y_val))\";\n",
       "                var nbb_formatted_code = \"# Define the input shape\\ninput_shape = (X_train_augmented_1000.shape[1],)\\n\\n# Define the model architecture using the hyperparameters\\nmodel_1000_aug = keras.Sequential()\\nmodel_1000_aug.add(\\n    Dense(\\n        units=best_hps_1000_aug.values[\\\"input_units\\\"],\\n        activation=best_hps_1000_aug.values[\\\"input_activation\\\"],\\n        input_shape=input_shape,\\n    )\\n)\\nfor i in range(best_hps_1000_aug.values[\\\"num_layers\\\"]):\\n    model_1000_aug.add(\\n        Dense(\\n            units=best_hps_1000_aug.values[f\\\"hidden_{i+1}_units\\\"],\\n            activation=best_hps_1000_aug.values[f\\\"hidden_{i+1}_activation\\\"],\\n        )\\n    )\\nmodel_1000_aug.add(Dense(units=2, activation=\\\"linear\\\"))\\n\\n# Compile the model using the hyperparameters\\noptimizer = tf.keras.optimizers.Adam(\\n    learning_rate=best_hps_1000_aug.values[\\\"learning_rate\\\"]\\n)\\nmodel_1000_aug.compile(\\n    optimizer=optimizer, loss=best_hps_1000_aug.values[\\\"loss\\\"], metrics=[\\\"mae\\\"]\\n)\\nearly_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Fit the model using the hyperparameters\\nhistory_1000_aug = model_1000_aug.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    batch_size=best_hps_1000_aug.values[\\\"batch_size\\\"],\\n    epochs=best_hps_1000_aug.values[\\\"num_epochs\\\"],\\n    callbacks=[early_stop],\\n    validation_data=(X_val_norm, y_val),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (X_train_augmented_1000.shape[1],)\n",
    "\n",
    "# Define the model architecture using the hyperparameters\n",
    "model_1000_aug = keras.Sequential()\n",
    "model_1000_aug.add(Dense(units=best_hps_1000_aug.values['input_units'], activation=best_hps_1000_aug.values['input_activation'], input_shape=input_shape))\n",
    "for i in range(best_hps_1000_aug.values['num_layers']):\n",
    "    model_1000_aug.add(Dense(units=best_hps_1000_aug.values[f'hidden_{i+1}_units'], activation=best_hps_1000_aug.values[f'hidden_{i+1}_activation']))\n",
    "model_1000_aug.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "# Compile the model using the hyperparameters\n",
    "optimizer = (tf.keras.optimizers.Adam(learning_rate=best_hps_1000_aug.values['learning_rate']))\n",
    "model_1000_aug.compile(optimizer=optimizer, loss=best_hps_1000_aug.values['loss'], metrics=['mae'])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Fit the model using the hyperparameters\n",
    "history_1000_aug = model_1000_aug.fit(X_train_augmented_1000, y_train_augmented_1000, batch_size=best_hps_1000_aug.values['batch_size'], epochs=best_hps_1000_aug.values['num_epochs'],callbacks=[early_stop], validation_data=(X_val_norm, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b19b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# Save the model\\nmodel_1000_aug.save(\\\"models/model_standard_1000_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Save the model\\nmodel_1000_aug.save(\\\"models/model_standard_1000_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the model\n",
    "model_1000_aug.save(\"models/model_standard_1000_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50809b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 910us/step - loss: 0.3338 - mae: 0.5021\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Load and Evaluate the model on the validation dataset\\nnew_model_1000_aug = tf.keras.models.load_model(\\n    \\\"models/model_standard_1000_augmented.h5\\\"\\n)\\nval_metrics_1000_aug = new_model_1000_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_formatted_code = \"# Load and Evaluate the model on the validation dataset\\nnew_model_1000_aug = tf.keras.models.load_model(\\n    \\\"models/model_standard_1000_augmented.h5\\\"\\n)\\nval_metrics_1000_aug = new_model_1000_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and Evaluate the model on the validation dataset\n",
    "new_model_1000_aug = tf.keras.models.load_model(\n",
    "    \"models/model_standard_1000_augmented.h5\"\n",
    ")\n",
    "val_metrics_1000_aug = new_model_1000_aug.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36a43782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 48)                3120      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,538\n",
      "Trainable params: 3,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"new_model_1000_aug.summary()\";\n",
       "                var nbb_formatted_code = \"new_model_1000_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_1000_aug.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29add98",
   "metadata": {},
   "source": [
    "### 5 Equivariant Neural Networks\n",
    "Train an equivariant neural network on the original dataset. To that end, you need to implement a custom model using the Keras Subclassing API. All layers except the output layer must have a weight matrix that looks as follows\n",
    "W` :=\n",
    "[\n",
    "[a b c b]\n",
    "[b a b c]\n",
    "[c b a b]\n",
    "[b c b a]\n",
    "]\n",
    "where a; b; c are the parameters that shall be learned. Moreover, equivariant layers have no bias vectors, i.e., you have b` = 0. The output layer of an equivariant network has a weight matrix WL :=\n",
    "[\n",
    "[d -d -d d]\n",
    "[-d -d d d]\n",
    "]\n",
    "\n",
    "with only one parameter d, and no bias unit as well. Apart from these specically structured weight matrices and the absence of bias vectors, equivariant networks look all like standard networks. However, they do not come as pre-implemented Keras layers, so you have to use the subclassing API. Once you have this, you can do anything else just as in case of the standard network. Save this model as model equivariant [m].h5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e657d",
   "metadata": {},
   "source": [
    "### Hypertuning Training dataset without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8893235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"custom_objects = {\\n    \\\"EquivariantOutputLayer\\\": EquivariantOutputLayer,\\n    \\\"EquivariantHiddenLayer\\\": EquivariantHiddenLayer,\\n}\";\n",
       "                var nbb_formatted_code = \"custom_objects = {\\n    \\\"EquivariantOutputLayer\\\": EquivariantOutputLayer,\\n    \\\"EquivariantHiddenLayer\\\": EquivariantHiddenLayer,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_objects = {\n",
    "    \"EquivariantOutputLayer\": EquivariantOutputLayer,\n",
    "    \"EquivariantHiddenLayer\": EquivariantHiddenLayer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define the tuner object\n",
    "tuner_5 = kt.Hyperband(\n",
    "    eq_build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"equivariant_nn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32109395",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_5.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the search\n",
    "tuner_5.search(X_train_1000_norm, y_train_1000,     validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop], epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dafa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps_enn = tuner_5.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_enn = tuner_5.hypermodel.build(best_hps_enn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps_enn.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb058ab",
   "metadata": {},
   "source": [
    "### Hypertuning Training dataset with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e33c38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 08s]\n",
      "val_loss: 0.3310951292514801\n",
      "\n",
      "Best val_loss So Far: 0.3290695250034332\n",
      "Total elapsed time: 00h 23m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"early_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define the tuner object\\ntuner_6 = kt.Hyperband(\\n    eq_build_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"equivariant_nn_aug\\\",\\n)\\n\\n# Start the search\\ntuner_6.search(X_train_augmented_1000, y_train_augmented_1000,     validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop], epochs=200)\";\n",
       "                var nbb_formatted_code = \"early_stop = EarlyStopping(monitor=\\\"val_loss\\\", patience=10)\\n\\n# Define the tuner object\\ntuner_6 = kt.Hyperband(\\n    eq_build_model,\\n    objective=\\\"val_loss\\\",\\n    max_epochs=200,\\n    factor=3,\\n    overwrite=True,\\n    directory=\\\"new_dir\\\",\\n    project_name=\\\"equivariant_nn_aug\\\",\\n)\\n\\n# Start the search\\ntuner_6.search(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[early_stop],\\n    epochs=200,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# Define the tuner object\n",
    "tuner_6 = kt.Hyperband(\n",
    "    eq_build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=200,\n",
    "    factor=3,\n",
    "    overwrite=True,\n",
    "    directory=\"new_dir\",\n",
    "    project_name=\"equivariant_nn_aug\",\n",
    ")\n",
    "\n",
    "# Start the search\n",
    "tuner_6.search(X_train_augmented_1000, y_train_augmented_1000,     validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stop], epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a9792b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"best_hps_enn_aug = tuner_6.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_enn_aug = tuner_6.hypermodel.build(best_hps_enn_aug)\\n# model_hp_enn_aug.values\";\n",
       "                var nbb_formatted_code = \"best_hps_enn_aug = tuner_6.get_best_hyperparameters(num_trials=1)[0]\\nmodel_hp_enn_aug = tuner_6.hypermodel.build(best_hps_enn_aug)\\n# model_hp_enn_aug.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps_enn_aug = tuner_6.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_hp_enn_aug = tuner_6.hypermodel.build(best_hps_enn_aug)\n",
    "# model_hp_enn_aug.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71420f0",
   "metadata": {},
   "source": [
    "#### Training and saving equivarant models with Hyperparamter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abb4e7",
   "metadata": {},
   "source": [
    "##### ENN for Training with 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48dcdccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Defining the Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_enn_100 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m      3\u001b[0m model_enn_100\u001b[38;5;241m.\u001b[39madd(EquivariantHiddenLayer())\n\u001b[0;32m      4\u001b[0m model_enn_100\u001b[38;5;241m.\u001b[39madd(EquivariantHiddenLayer())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Defining the Model\n",
    "model_enn_100 = tf.keras.Sequential()\n",
    "model_enn_100.add(EquivariantHiddenLayer())\n",
    "model_enn_100.add(EquivariantHiddenLayer())\n",
    "model_enn_100.add(EquivariantOutputLayer())\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model_enn_100.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps_enn.get(\"learning_rate\")),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_absolute_error\"],\n",
    ")\n",
    "model_enn_100.fit(\n",
    "    X_train_100_norm,\n",
    "    y_train_100,\n",
    "    epochs=best_hps_enn.get(\"num_epochs\"),\n",
    "    batch_size=best_hps_enn.get(\"batch_size\"),\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "model_enn_100.save(\"models/model_equivariant_100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b10248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enn_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model using the custom object scope\n",
    "load_model_model_enn_100 = tf.keras.models.load_model(\"models/model_equivariant_100.h5\",custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7019f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valmet_model_enn_100 = load_model_model_enn_100.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b635ec",
   "metadata": {},
   "source": [
    "##### ENN for Training with 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7895670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_hps_enn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m model_enn_1000\u001b[38;5;241m.\u001b[39madd(EquivariantOutputLayer())\n\u001b[0;32m      7\u001b[0m stop_early \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      9\u001b[0m model_enn_1000\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m---> 10\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[43mbest_hps_enn\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     11\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m model_enn_1000\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     15\u001b[0m     X_train_1000_norm,\n\u001b[0;32m     16\u001b[0m     y_train_1000,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[stop_early],\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m model_enn_1000\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/model_equivariant_1000.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_hps_enn' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Defining the Model\\nmodel_enn_1000 = tf.keras.Sequential()\\nmodel_enn_1000.add(EquivariantHiddenLayer())\\nmodel_enn_1000.add(EquivariantHiddenLayer())\\nmodel_enn_1000.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_1000.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps_enn.get(\\\"learning_rate\\\")),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_1000.fit(\\n    X_train_1000_norm,\\n    y_train_1000,\\n    epochs=best_hps_enn.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_1000.save(\\\"models/model_equivariant_1000.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Defining the Model\\nmodel_enn_1000 = tf.keras.Sequential()\\nmodel_enn_1000.add(EquivariantHiddenLayer())\\nmodel_enn_1000.add(EquivariantHiddenLayer())\\nmodel_enn_1000.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_1000.compile(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps_enn.get(\\\"learning_rate\\\")),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_1000.fit(\\n    X_train_1000_norm,\\n    y_train_1000,\\n    epochs=best_hps_enn.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_1000.save(\\\"models/model_equivariant_1000.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the Model\n",
    "model_enn_1000 = tf.keras.Sequential()\n",
    "model_enn_1000.add(EquivariantHiddenLayer())\n",
    "model_enn_1000.add(EquivariantHiddenLayer())\n",
    "model_enn_1000.add(EquivariantOutputLayer())\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model_enn_1000.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=best_hps_enn.get(\"learning_rate\")),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_absolute_error\"],\n",
    ")\n",
    "model_enn_1000.fit(\n",
    "    X_train_1000_norm,\n",
    "    y_train_1000,\n",
    "    epochs=best_hps_enn.get(\"num_epochs\"),\n",
    "    batch_size=best_hps_enn.get(\"batch_size\"),\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "model_enn_1000.save(\"models/model_equivariant_1000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96489be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enn_1000.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec924ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model using the custom object scope\n",
    "load_model_model_enn_1000 = tf.keras.models.load_model(\"models/model_equivariant_1000.h5\",custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "valmet_enn_1000 = load_model_model_enn_1000.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709b86a",
   "metadata": {},
   "source": [
    "##### ENN for Training with Augmented data for 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a36406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 63ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3310 - val_mean_absolute_error: 0.5003\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3310 - val_mean_absolute_error: 0.5003\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3449 - mean_absolute_error: 0.5084 - val_loss: 0.3310 - val_mean_absolute_error: 0.5004\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Defining the Model\\nmodel_enn_100_aug = tf.keras.Sequential()\\nmodel_enn_100_aug.add(EquivariantHiddenLayer())\\nmodel_enn_100_aug.add(EquivariantHiddenLayer())\\nmodel_enn_100_aug.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_100_aug.compile(\\n    optimizer=tf.keras.optimizers.Adam(\\n        learning_rate=best_hps_enn_aug.get(\\\"learning_rate\\\")\\n    ),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_100_aug.fit(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=best_hps_enn_aug.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn_aug.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_100_aug.save(\\\"models/model_equivariant_100_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Defining the Model\\nmodel_enn_100_aug = tf.keras.Sequential()\\nmodel_enn_100_aug.add(EquivariantHiddenLayer())\\nmodel_enn_100_aug.add(EquivariantHiddenLayer())\\nmodel_enn_100_aug.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_100_aug.compile(\\n    optimizer=tf.keras.optimizers.Adam(\\n        learning_rate=best_hps_enn_aug.get(\\\"learning_rate\\\")\\n    ),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_100_aug.fit(\\n    X_train_augmented,\\n    y_train_augmented,\\n    epochs=best_hps_enn_aug.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn_aug.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_100_aug.save(\\\"models/model_equivariant_100_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the Model\n",
    "model_enn_100_aug = tf.keras.Sequential()\n",
    "model_enn_100_aug.add(EquivariantHiddenLayer())\n",
    "model_enn_100_aug.add(EquivariantHiddenLayer())\n",
    "model_enn_100_aug.add(EquivariantOutputLayer())\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model_enn_100_aug.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=best_hps_enn_aug.get(\"learning_rate\")\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_absolute_error\"],\n",
    ")\n",
    "model_enn_100_aug.fit(\n",
    "    X_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=best_hps_enn_aug.get(\"num_epochs\"),\n",
    "    batch_size=best_hps_enn_aug.get(\"batch_size\"),\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "model_enn_100_aug.save(\"models/model_equivariant_100_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf821762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " equivariant_hidden_layer_4   (None, 4)                3         \n",
      " (EquivariantHiddenLayer)                                        \n",
      "                                                                 \n",
      " equivariant_hidden_layer_5   (None, 4)                3         \n",
      " (EquivariantHiddenLayer)                                        \n",
      "                                                                 \n",
      " equivariant_output_layer_2   (None, 2)                1         \n",
      " (EquivariantOutputLayer)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"model_enn_100_aug.summary()\";\n",
       "                var nbb_formatted_code = \"model_enn_100_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_enn_100_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63942ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# load the model using the custom object scope\\nload_model_model_enn_100_aug = tf.keras.models.load_model(\\\"models/model_equivariant_100_augmented.h5\\\",custom_objects=custom_objects)\";\n",
       "                var nbb_formatted_code = \"# load the model using the custom object scope\\nload_model_model_enn_100_aug = tf.keras.models.load_model(\\n    \\\"models/model_equivariant_100_augmented.h5\\\", custom_objects=custom_objects\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model using the custom object scope\n",
    "load_model_model_enn_100_aug = tf.keras.models.load_model(\"models/model_equivariant_100_augmented.h5\",custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "242b9637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 940us/step - loss: 0.3310 - mean_absolute_error: 0.5004\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"valmet_load_model_model_enn_100_aug = load_model_model_enn_100_aug.evaluate(\\n    X_val_norm, y_val\\n)\";\n",
       "                var nbb_formatted_code = \"valmet_load_model_model_enn_100_aug = load_model_model_enn_100_aug.evaluate(\\n    X_val_norm, y_val\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valmet_load_model_model_enn_100_aug = load_model_model_enn_100_aug.evaluate(\n",
    "    X_val_norm, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae989ced",
   "metadata": {},
   "source": [
    "##### ENN for Training with Augmented data for 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "630a32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 0.3362 - mean_absolute_error: 0.5052 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3362 - mean_absolute_error: 0.5052 - val_loss: 0.3318 - val_mean_absolute_error: 0.5009\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3363 - mean_absolute_error: 0.5052 - val_loss: 0.3318 - val_mean_absolute_error: 0.5009\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3362 - mean_absolute_error: 0.5052 - val_loss: 0.3312 - val_mean_absolute_error: 0.5005\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3362 - mean_absolute_error: 0.5052 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3362 - mean_absolute_error: 0.5052 - val_loss: 0.3311 - val_mean_absolute_error: 0.5004\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Defining the Model\\nmodel_enn_1000_aug = tf.keras.Sequential()\\nmodel_enn_1000_aug.add(EquivariantHiddenLayer())\\nmodel_enn_1000_aug.add(EquivariantHiddenLayer())\\nmodel_enn_1000_aug.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_1000_aug.compile(\\n    optimizer=tf.keras.optimizers.Adam(\\n        learning_rate=best_hps_enn_aug.get(\\\"learning_rate\\\")\\n    ),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_1000_aug.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=best_hps_enn_aug.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn_aug.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_1000_aug.save(\\\"models/model_equivariant_1000_augmented.h5\\\")\";\n",
       "                var nbb_formatted_code = \"# Defining the Model\\nmodel_enn_1000_aug = tf.keras.Sequential()\\nmodel_enn_1000_aug.add(EquivariantHiddenLayer())\\nmodel_enn_1000_aug.add(EquivariantHiddenLayer())\\nmodel_enn_1000_aug.add(EquivariantOutputLayer())\\n\\nstop_early = tf.keras.callbacks.EarlyStopping(monitor=\\\"val_loss\\\", patience=5)\\n\\nmodel_enn_1000_aug.compile(\\n    optimizer=tf.keras.optimizers.Adam(\\n        learning_rate=best_hps_enn_aug.get(\\\"learning_rate\\\")\\n    ),\\n    loss=\\\"mean_squared_error\\\",\\n    metrics=[\\\"mean_absolute_error\\\"],\\n)\\nmodel_enn_1000_aug.fit(\\n    X_train_augmented_1000,\\n    y_train_augmented_1000,\\n    epochs=best_hps_enn_aug.get(\\\"num_epochs\\\"),\\n    batch_size=best_hps_enn_aug.get(\\\"batch_size\\\"),\\n    validation_data=(X_val_norm, y_val),\\n    callbacks=[stop_early],\\n)\\nmodel_enn_1000_aug.save(\\\"models/model_equivariant_1000_augmented.h5\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the Model\n",
    "model_enn_1000_aug = tf.keras.Sequential()\n",
    "model_enn_1000_aug.add(EquivariantHiddenLayer())\n",
    "model_enn_1000_aug.add(EquivariantHiddenLayer())\n",
    "model_enn_1000_aug.add(EquivariantOutputLayer())\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model_enn_1000_aug.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=best_hps_enn_aug.get(\"learning_rate\")\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"mean_absolute_error\"],\n",
    ")\n",
    "model_enn_1000_aug.fit(\n",
    "    X_train_augmented_1000,\n",
    "    y_train_augmented_1000,\n",
    "    epochs=best_hps_enn_aug.get(\"num_epochs\"),\n",
    "    batch_size=best_hps_enn_aug.get(\"batch_size\"),\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[stop_early],\n",
    ")\n",
    "model_enn_1000_aug.save(\"models/model_equivariant_1000_augmented.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf6ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " equivariant_hidden_layer_6   (None, 4)                3         \n",
      " (EquivariantHiddenLayer)                                        \n",
      "                                                                 \n",
      " equivariant_hidden_layer_7   (None, 4)                3         \n",
      " (EquivariantHiddenLayer)                                        \n",
      "                                                                 \n",
      " equivariant_output_layer_3   (None, 2)                1         \n",
      " (EquivariantOutputLayer)                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"model_enn_1000_aug.summary()\";\n",
       "                var nbb_formatted_code = \"model_enn_1000_aug.summary()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_enn_1000_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaa67645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# load the model using the custom object scope\\nload_model_enn_1000_aug = tf.keras.models.load_model(\\\"models/model_equivariant_1000_augmented.h5\\\",custom_objects=custom_objects)\";\n",
       "                var nbb_formatted_code = \"# load the model using the custom object scope\\nload_model_enn_1000_aug = tf.keras.models.load_model(\\n    \\\"models/model_equivariant_1000_augmented.h5\\\", custom_objects=custom_objects\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model using the custom object scope\n",
    "load_model_enn_1000_aug = tf.keras.models.load_model(\"models/model_equivariant_1000_augmented.h5\",custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a6b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 929us/step - loss: 0.3311 - mean_absolute_error: 0.5004\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"valmet_model_enn_1000_aug = load_model_enn_1000_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_formatted_code = \"valmet_model_enn_1000_aug = load_model_enn_1000_aug.evaluate(X_val_norm, y_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valmet_model_enn_1000_aug = load_model_enn_1000_aug.evaluate(X_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ab982",
   "metadata": {},
   "source": [
    "#### Check the weights a, b,c and d of the ENN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in load_model_model_enn_100.layers:\n",
    "    print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in load_model_model_enn_1000.layers:\n",
    "    print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_enn_100_aug.layers:\n",
    "    print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141abd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_enn_1000_aug.layers:\n",
    "    print(layer.get_config(), layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f0ec8",
   "metadata": {},
   "source": [
    "#### Which model worked best depending on the size of the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64e522",
   "metadata": {},
   "source": [
    "The model that is trained for 1000 Samples without augmentation using standard model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d9d74",
   "metadata": {},
   "source": [
    "####  In which cases did data augmentation enhance the performace?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2c519",
   "metadata": {},
   "source": [
    "Better results are observed with more data samples using standard model definition, generated through data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01049bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
